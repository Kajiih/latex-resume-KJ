% Experience section
\companyNameAndLocationHeading{
    SNU Vision \& Learning Lab
}{
    Seoul, South Korea
}
\titleAndDateHeading{
    Researcher
}{
    November 2022 \textbf{--} June 2024
}
\outerBulletListStart{}
\bulletItem{
    Experimented reinforcement learning with human feedbacks (RLHF) to improve quality and alignment of unsupervised skill discovery in 2 embodied environments (iTHOR, Crafter).
    Fully implemented graphical based skill extraction (HRL) method in JAX/Flax and improved training speed by 2 to 4 times.
    Introduced and formed other researchers to JAX framework with \~25\% adoption in the lab within the following year.
}
\bulletItem{
    Lead modeling and development of an embodied RL environment based on AI2THOR focused on scalable  multi-task training with predicate based task evaluation.
    Deployed containers (Docker) to run Unity based simulator with X11 server on headless cluster and train RL agents.
    Optimized task evaluation algorithm and reduced overhead to 1.7\% of the raw AI2THOR simulation. Designed 14 complex RL tasks and showed 80\% relative improvement when using the predicate based evaluation.
    Paper currently in review process at ICRA 2025.
}
\outerBulletListEnd{}

\companyNameAndLocationHeading{
    Apex Solutions
}{
    Figeac, France
}
\titleAndDateHeading{
    Research internship
}{
    June 2022 \textbf{--} August 2022
}
\outerBulletListStart{}
\bulletItem{
    Started \textbf{modeling and development of a mulit-agent environment} for the \textbf{simulation of intrusion in critical infrastructures} (Python, Gym/Gymnasium).
    Base environment still in use within following research projects.
}
\bulletItem{
    Designed and implemented \textbf{Reinforcement Learning (RL) benchmarks} for multi-agent red team penetration and blue team defense (capture the flag) with limited information sharing.
    Evaluation and experimentation of RL algorithms with adaptations for multi-agent settings (PyTorch, Stable-Baselines3).
}
\outerBulletListEnd{}


% \iftoggle{is_long_version}
% {
%     \companyNameAndLocationHeading{}
%     {Autonomous Systems Laboratory}{Ithaca, NY}
%     \titleAndDateHeading{}
%     {Mechanical Engineering Researcher}{August 2014 \textbf{--} December 2014}
%     \outerBulletListStart{}
%     \bulletItem{Developed and wrote Python handlers to control a robotic ball, Sphero, with a path planning program, LTLMoP.}
%     \bulletItem{Successfully demoed the code, having Sphero autonomously traverse a map and react to its environment.}

%     \innerBulletListStart{}
%     \bulletItem{Co-implemented and \textbf{patented a novel Contingency MPC} for handling multi-modal predictions in trajectory optimizer, refactoring solver formulation to support joint optimization with minimal latency overhead.}
%     \bulletItem{Invented novel algorithm for generating \textbf{assertive lane change} trajectories via \enquote{gap matching} behavior to signal intent. Redesigned Planning/Control interface (C++) and added visualizations to support new feature.}
%     \bulletItem{\textbf{Tuned MPC} weights and enhanced cost function, contributing to investor analysts’ feedback that the ride was \textbf{\enquote{smoother than Waymo’s}}. First tuned in open-loop sim to match human driving, later fine-tuning on vehicle.}
%     \innerBulletListEnd{}

%     \outerBulletListEnd{}
% }{}
